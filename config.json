{
  "$schema": "https://opencode.ai/config.json",
  "model": "llama.cpp/{env:LLAMA_MODEL}",
  "provider": {
    "llama.cpp": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "llama-server (local)",
      "options": {
        "baseURL": "{env:LLAMA_SERVER_URL}"
      },
      "models": {
        "{env:LLAMA_MODEL}": {
          "name": "{env:LLAMA_MODEL}"
        }
      }
    }
  }
}
